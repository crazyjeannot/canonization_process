{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b81ead65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import set_config, metrics\n",
    "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import Normalizer, StandardScaler\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, train_test_split, ShuffleSplit, LeaveOneGroupOut, LeavePGroupsOut\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66be36c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c151327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fold_0 = pd.read_csv(r'data/fold_0.csv').set_index(\"index\")\n",
    "df_fold_1 = pd.read_csv(r'data/fold_1.csv').set_index(\"index\")\n",
    "df_fold_2 = pd.read_csv(r'data/fold_2.csv').set_index(\"index\")\n",
    "df_fold_3 = pd.read_csv(r'data/fold_3.csv').set_index(\"index\")\n",
    "df_fold_4 = pd.read_csv(r'data/fold_4.csv').set_index(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4258269c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [df_fold_0, df_fold_1, df_fold_2, df_fold_3, df_fold_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c59b1074",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_canon    0.587054\n",
      "canon        0.412946\n",
      "Name: canon, dtype: float64\n",
      "canon        0.501773\n",
      "non_canon    0.498227\n",
      "Name: canon, dtype: float64\n",
      "non_canon    0.525046\n",
      "canon        0.474954\n",
      "Name: canon, dtype: float64\n",
      "non_canon    0.581888\n",
      "canon        0.418112\n",
      "Name: canon, dtype: float64\n",
      "non_canon    0.578182\n",
      "canon        0.421818\n",
      "Name: canon, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df_fold_0.canon.value_counts(normalize=True))\n",
    "print(df_fold_1.canon.value_counts(normalize=True))\n",
    "print(df_fold_2.canon.value_counts(normalize=True))\n",
    "print(df_fold_3.canon.value_counts(normalize=True))\n",
    "print(df_fold_4.canon.value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7a14c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def canonizer(data, test_size=0.2, random_state=42, sampling=None, cross_validation=False, cv=5, kernel='rbf', nb_coef=20):\n",
    "    list_df_scores = []\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), Normalizer(), SVC(kernel=kernel, probability=True, class_weight='balanced'))\n",
    "    \n",
    "    \n",
    "    for elem in data:\n",
    "        train = elem.head(int(len(elem)*(1-test_size)))\n",
    "        test = elem.iloc[len(train.index):]  \n",
    "        X_train = train.drop(['canon'], axis=1)\n",
    "        y_train = train['canon']\n",
    "        X_test = test.drop(['canon'], axis=1)\n",
    "        y_test = test['canon']\n",
    "                \n",
    "        pipe.fit(X_train, y_train)\n",
    "        report = metrics.classification_report(y_test, pipe.predict(X_test), output_dict=True)\n",
    "        df_scores = pd.DataFrame(report).transpose()\n",
    "        print(df_scores)\n",
    "        list_df_scores.append(df_scores)\n",
    "    \n",
    "    df_final_scores = pd.concat(list_df_scores).groupby(level=0).mean()\n",
    "    \n",
    "    return pipe, df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "014b6675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score    support\n",
      "canon          0.800000  0.827586  0.813559  29.000000\n",
      "non_canon      0.916667  0.901639  0.909091  61.000000\n",
      "accuracy       0.877778  0.877778  0.877778   0.877778\n",
      "macro avg      0.858333  0.864613  0.861325  90.000000\n",
      "weighted avg   0.879074  0.877778  0.878309  90.000000\n",
      "              precision    recall  f1-score     support\n",
      "canon          0.969072  0.949495  0.959184   99.000000\n",
      "non_canon      0.687500  0.785714  0.733333   14.000000\n",
      "accuracy       0.929204  0.929204  0.929204    0.929204\n",
      "macro avg      0.828286  0.867605  0.846259  113.000000\n",
      "weighted avg   0.934187  0.929204  0.931202  113.000000\n",
      "              precision    recall  f1-score     support\n",
      "canon          0.809524  0.283333  0.419753   60.000000\n",
      "non_canon      0.505747  0.916667  0.651852   48.000000\n",
      "accuracy       0.564815  0.564815  0.564815    0.564815\n",
      "macro avg      0.657635  0.600000  0.535802  108.000000\n",
      "weighted avg   0.674512  0.564815  0.522908  108.000000\n",
      "              precision    recall  f1-score     support\n",
      "canon          0.666667  0.380952  0.484848   42.000000\n",
      "non_canon      0.675000  0.870968  0.760563   62.000000\n",
      "accuracy       0.673077  0.673077  0.673077    0.673077\n",
      "macro avg      0.670833  0.625960  0.622706  104.000000\n",
      "weighted avg   0.671635  0.673077  0.649217  104.000000\n",
      "              precision    recall  f1-score     support\n",
      "canon          0.241379  0.166667  0.197183   42.000000\n",
      "non_canon      0.567901  0.676471  0.617450   68.000000\n",
      "accuracy       0.481818  0.481818  0.481818    0.481818\n",
      "macro avg      0.404640  0.421569  0.407316  110.000000\n",
      "weighted avg   0.443229  0.481818  0.456984  110.000000\n"
     ]
    }
   ],
   "source": [
    "pipe, df_final_scores = canonizer(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6e9684b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.696886</td>\n",
       "      <td>0.696886</td>\n",
       "      <td>0.696886</td>\n",
       "      <td>0.696886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canon</th>\n",
       "      <td>0.703204</td>\n",
       "      <td>0.478059</td>\n",
       "      <td>0.541577</td>\n",
       "      <td>54.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.676638</td>\n",
       "      <td>0.669897</td>\n",
       "      <td>0.637580</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_canon</th>\n",
       "      <td>0.650072</td>\n",
       "      <td>0.861734</td>\n",
       "      <td>0.733583</td>\n",
       "      <td>50.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.718791</td>\n",
       "      <td>0.696886</td>\n",
       "      <td>0.673068</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "accuracy       0.696886  0.696886  0.696886    0.696886\n",
       "canon          0.703204  0.478059  0.541577   54.400000\n",
       "macro avg      0.676638  0.669897  0.637580  105.000000\n",
       "non_canon      0.650072  0.861734  0.733583   50.600000\n",
       "weighted avg   0.718791  0.696886  0.673068  105.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8065f7c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.705338</td>\n",
       "      <td>0.705338</td>\n",
       "      <td>0.705338</td>\n",
       "      <td>0.705338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>canon</th>\n",
       "      <td>0.697328</td>\n",
       "      <td>0.521607</td>\n",
       "      <td>0.574906</td>\n",
       "      <td>54.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.683946</td>\n",
       "      <td>0.675949</td>\n",
       "      <td>0.654682</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_canon</th>\n",
       "      <td>0.670563</td>\n",
       "      <td>0.830292</td>\n",
       "      <td>0.734458</td>\n",
       "      <td>50.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.720527</td>\n",
       "      <td>0.705338</td>\n",
       "      <td>0.687724</td>\n",
       "      <td>105.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "accuracy       0.705338  0.705338  0.705338    0.705338\n",
       "canon          0.697328  0.521607  0.574906   54.400000\n",
       "macro avg      0.683946  0.675949  0.654682  105.000000\n",
       "non_canon      0.670563  0.830292  0.734458   50.600000\n",
       "weighted avg   0.720527  0.705338  0.687724  105.000000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ab4461",
   "metadata": {},
   "source": [
    "### Let's try Leave One Group Out Cross Validation (leave one author out, predict canonicity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8a06bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main = pd.read_csv(r'data/unigram_dataset_majed_canon_author_scale.csv')\n",
    "\n",
    "df_main.set_index(\"index\", inplace = True)\n",
    "df_main = df_main.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "accb9604",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_author = []\n",
    "for elem in df_main.index:\n",
    "    list_author.append(elem.split('_')[1])\n",
    "    \n",
    "df_main['auteur'] = list_author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "facea213",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "714"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(list_author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0cad4f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_concat = pd.concat([df_main.iloc[:, 0:800], df_main.iloc[:, 1000:1800]],  axis=1)#df_main.iloc[:, 3156:3956]],\n",
    "df_concat['canon']=df_main['canon']\n",
    "df_concat['auteur']=df_main['auteur']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d9393b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4dd78c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd12fffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LOGO_canonized(df_main, sampling=None):\n",
    "    \n",
    "    ALL_PREDS, ALL_GT = [], [] # lists of all predictions and all ground truth data\n",
    "    set_auteur = len(set(list(df_main.auteur)))\n",
    "    \n",
    "    pipe = make_pipeline(StandardScaler(), SVC(class_weight={\"canon\":1.5, \"non_canon\":1})) #probability=True\n",
    "    logo = LeaveOneGroupOut()\n",
    "    \n",
    "    \n",
    "    for (train_index, test_index) in tqdm(logo.split(df_main.drop(['auteur', 'canon'], axis=1), df_main['canon'], df_main['auteur']), total=set_auteur): \n",
    "        \n",
    "        train = df_main.iloc[train_index]\n",
    "        test = df_main.iloc[test_index]\n",
    "        \n",
    "        #print(f\"\\n AUTHOR OUT {i} : \"+test.index[0].split('_')[1]+\" \\n\")\n",
    "\n",
    "        X_train = train.drop(['auteur', 'canon'], axis=1)\n",
    "        y_train = train['canon']\n",
    "        X_test = test.drop(['auteur', 'canon'], axis=1)\n",
    "        y_test = test['canon']\n",
    "        \n",
    "        if sampling is not None:     \n",
    "                if sampling == 'over':\n",
    "                    ros = RandomOverSampler(random_state=10)\n",
    "                    X_resampled, y_resampled = ros.fit_resample(X_train, y_train)\n",
    "                    \n",
    "                elif sampling == 'svm':\n",
    "                    sm = SVMSMOTE(random_state=10)\n",
    "                    X_resampled, y_resampled = sm.fit_resample(X_train, y_train)\n",
    "                    \n",
    "                elif sampling == 'under':\n",
    "                    rus = RandomUnderSampler(random_state=10)\n",
    "                    X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "                    \n",
    "                elif sampling == \"smoteenn\":\n",
    "                    smote_enn = SMOTEENN(random_state=10)\n",
    "                    X_resampled, y_resampled = smote_enn.fit_resample(X_train, y_train)\n",
    "                    \n",
    "                elif sampling == 'smotetomek':\n",
    "                    smote_tomek = SMOTETomek(random_state=10)\n",
    "                    X_resampled, y_resampled = smote_tomek.fit_resample(X_train, y_train)\n",
    "                \n",
    "                else:\n",
    "                    print('Please follow the sampling possible values : over, under, smoteenn, smotetomek')\n",
    "                    return\n",
    "                    \n",
    "                print('Resampled dataset shape {}'.format(Counter(y_resampled)))\n",
    "            \n",
    "                pipe.fit(X_resampled, y_resampled)\n",
    "        \n",
    "        else:\n",
    "                pipe.fit(X_train, y_train)\n",
    "                \n",
    "                \n",
    "        preds = pipe.predict(X_test)\n",
    "        \n",
    "        #print(f\"\\n PREDS : \")\n",
    "        #print(set(zip(test.index, preds)))\n",
    "        #print(\"\\n\\n\")\n",
    "        \n",
    "        ALL_PREDS.extend(preds)\n",
    "        ALL_GT.extend(y_test)\n",
    "    \n",
    "    report = metrics.classification_report(ALL_GT, ALL_PREDS, output_dict=True)# zero_division=1\n",
    "    df_scores = pd.DataFrame(report).transpose()\n",
    "    #print(df_scores)\n",
    "    \n",
    "    return pipe, df_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f9c0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab2968c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b25e12a246548d187f9eda81401245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/714 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "NameError",
     "evalue": "name 'RandomUnderSampler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m pipe, df_final_scores \u001b[38;5;241m=\u001b[39m \u001b[43mLOGO_canonized\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_concat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43munder\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mLOGO_canonized\u001b[0;34m(df_main, sampling)\u001b[0m\n\u001b[1;32m     29\u001b[0m     X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m sm\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124munder\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 32\u001b[0m     rus \u001b[38;5;241m=\u001b[39m \u001b[43mRandomUnderSampler\u001b[49m(random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     33\u001b[0m     X_resampled, y_resampled \u001b[38;5;241m=\u001b[39m rus\u001b[38;5;241m.\u001b[39mfit_resample(X_train, y_train)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m sampling \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msmoteenn\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'RandomUnderSampler' is not defined"
     ]
    }
   ],
   "source": [
    "pipe, df_final_scores = LOGO_canonized(df_concat, sampling='under')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f696064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "455addf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canon</th>\n",
       "      <td>0.712209</td>\n",
       "      <td>0.626598</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1173.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_canon</th>\n",
       "      <td>0.772822</td>\n",
       "      <td>0.833800</td>\n",
       "      <td>0.802153</td>\n",
       "      <td>1787.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.751689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.742515</td>\n",
       "      <td>0.730199</td>\n",
       "      <td>0.734410</td>\n",
       "      <td>2960.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.748802</td>\n",
       "      <td>0.751689</td>\n",
       "      <td>0.748462</td>\n",
       "      <td>2960.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "canon          0.712209  0.626598  0.666667  1173.000000\n",
       "non_canon      0.772822  0.833800  0.802153  1787.000000\n",
       "accuracy       0.751689  0.751689  0.751689     0.751689\n",
       "macro avg      0.742515  0.730199  0.734410  2960.000000\n",
       "weighted avg   0.748802  0.751689  0.748462  2960.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c20e0c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa793da0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter author w/ more than 5 texts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e74f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d12eeb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_N_novel_per_author(list_author, N):\n",
    "    author_selected = []\n",
    "    dict_author = dict(Counter(list_author))\n",
    "    for key, value in dict_author.items():\n",
    "        if value >= N:\n",
    "            author_selected.append(key)\n",
    "    return author_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d42c2373",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_selected = select_N_novel_per_author(list_author, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8a464eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_main_selected = df_main.loc[df_main['auteur'].isin(author_selected)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8f7d0ed6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "non_canon    1041\n",
       "canon         957\n",
       "Name: canon, dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_main_selected.canon.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fcf1ad8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c0fb01b5c44dd9ba3a41cb4308dc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipe, df_final_scores = LOGO_canonized(df_main_selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0f57f922",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>canon</th>\n",
       "      <td>0.733407</td>\n",
       "      <td>0.692790</td>\n",
       "      <td>0.712520</td>\n",
       "      <td>957.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>non_canon</th>\n",
       "      <td>0.731261</td>\n",
       "      <td>0.768492</td>\n",
       "      <td>0.749415</td>\n",
       "      <td>1041.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.732232</td>\n",
       "      <td>0.732232</td>\n",
       "      <td>0.732232</td>\n",
       "      <td>0.732232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.732334</td>\n",
       "      <td>0.730641</td>\n",
       "      <td>0.730967</td>\n",
       "      <td>1998.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.732289</td>\n",
       "      <td>0.732232</td>\n",
       "      <td>0.731743</td>\n",
       "      <td>1998.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score      support\n",
       "canon          0.733407  0.692790  0.712520   957.000000\n",
       "non_canon      0.731261  0.768492  0.749415  1041.000000\n",
       "accuracy       0.732232  0.732232  0.732232     0.732232\n",
       "macro avg      0.732334  0.730641  0.730967  1998.000000\n",
       "weighted avg   0.732289  0.732232  0.731743  1998.000000"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560d02ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
